services:
  kafka:
    container_name: kafka
    image: "apache/kafka:latest"
    environment:
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_NODE_ID=0
      - KAFKA_LISTENERS=PLAINTEXT://:9092,EXTERNAL://:9094,CONTROLLER://:9093
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_NUM_PARTITIONS=1
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_HEAP_OPTS=-Xms256m -Xmx512m
      - KAFKA_JVM_PERFORMANCE_OPTS=-XX:MaxRAMPercentage=60
    volumes:
      - kafka_data:/var/lib/kafka/data
    ports:
      - 127.0.0.1:9092:9092
      - 127.0.0.1:9094:9094
    deploy:
      resources:
        limits:
          memory: 768M
          cpus: "1.0"

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on: [kafka]
    ports:
      - "127.0.0.1:8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=sid45
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      - JAVA_TOOL_OPTIONS=-Xms64m -Xmx192m

  spark-master:
    build:
      context: ./spark
      dockerfile: Dockerfile
    image: sidi-spark:3.5.3-py311
    container_name: spark-master
    command:
      - /opt/spark/bin/spark-class
      - org.apache.spark.deploy.master.Master
      - --host
      - spark-master
      - --port
      - "7077"
      - --webui-port
      - "8080"
    ports:
      - "127.0.0.1:7077:7077"
      - "127.0.0.1:8081:8080"
    volumes:
      - ./spark:/opt/spark/conf
      - ./data:/workspace/data
      - ./checkpoints:/workspace/checkpoints
    environment:
      - SPARK_DAEMON_MEMORY=512m
      - PYSPARK_PYTHON=/usr/bin/python3.11

  spark-worker-1:
    image: sidi-spark:3.5.3-py311
    container_name: spark-worker-1
    depends_on: [spark-master]
    command:
      - /opt/spark/bin/spark-class
      - org.apache.spark.deploy.worker.Worker
      - spark://spark-master:7077
      - --webui-port
      - "8081"
    ports:
      - "127.0.0.1:8082:8081"
    volumes:
      - ./data:/workspace/data
      - ./checkpoints:/workspace/checkpoints
    environment:
      - SPARK_DAEMON_MEMORY=1024m
      - PYSPARK_PYTHON=/usr/bin/python3.11

  jupyter:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: jupyter
    depends_on: [spark-master, kafka]
    ports:
      - "127.0.0.1:8888:8888"
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=ChangeMeStrong
      - SPARK_MASTER=spark://spark-master:7077
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - PYSPARK_SUBMIT_ARGS=--conf spark.pyspark.python=/usr/bin/python3.11 --conf spark.pyspark.driver.python=/opt/conda/bin/python --conf spark.driver.memory=1024m --conf spark.executor.memory=1024m --conf spark.sql.shuffle.partitions=4 --master spark://spark-master:7077 --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3,org.apache.kafka:kafka-clients:3.5.1 pyspark-shell
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./data:/workspace/data
      - ./checkpoints:/workspace/checkpoints

volumes:
  kafka_data: